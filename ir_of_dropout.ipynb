{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_IR_DEBUG=1\n",
      "env: XLA_HLO_DEBUG=1\n"
     ]
    }
   ],
   "source": [
    "%env XLA_IR_DEBUG=1\n",
    "%env XLA_HLO_DEBUG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch_xla.device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetRngSeed of device 0x55e4ac9fc260\n",
      "Init seed value from scalar: 709230394\n",
      "Update seed to: 151784526842133\n",
      "HloModule IrToHlo.49, entry_computation_layout={(f32[], s64[], bf16[], bf16[3]{0})->(bf16[3]{0})}\n",
      "\n",
      "ENTRY %IrToHlo.49 (p0.1: f32[], p1.2: s64[], p2.7: bf16[], p3.44: bf16[3]) -> (bf16[3]) {\n",
      "  %constant.5 = s64[] constant(2531011), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.3 = s64[] constant(214013), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p1.2 = s64[] parameter(1), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.4 = s64[] multiply(s64[] %constant.3, s64[] %p1.2), metadata={op_type=\"aten__mul\" op_name=\"aten__mul\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %add.6 = s64[] add(s64[] %constant.5, s64[] %multiply.4), metadata={op_type=\"aten__add\" op_name=\"aten__add\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.14 = u64[] convert(s64[] %add.6), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.18 = u64[1]{0} reshape(u64[] %convert.14), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.17 = u64[] constant(0), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.19 = u64[1]{0} reshape(u64[] %constant.17), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %concatenate.20 = u64[2]{0} concatenate(u64[1]{0} %reshape.18, u64[1]{0} %reshape.19), dimensions={0}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %rng-bit-generator.21 = (u64[2]{0}, u8[3]{0}) rng-bit-generator(u64[2]{0} %concatenate.20), algorithm=rng_default, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %get-tuple-element.23 = u64[2]{0} get-tuple-element((u64[2]{0}, u8[3]{0}) %rng-bit-generator.21), index=0, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p3.44 = bf16[3]{0} parameter(3), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/utils/_device.py\" source_line=106}\n",
      "  %convert.45 = f32[3]{0} convert(bf16[3]{0} %p3.44), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %get-tuple-element.22 = u8[3]{0} get-tuple-element((u64[2]{0}, u8[3]{0}) %rng-bit-generator.21), index=1, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.24 = u8[] constant(1), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.25 = u8[3]{0} broadcast(u8[] %constant.24), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %shift-right-logical.26 = u8[3]{0} shift-right-logical(u8[3]{0} %get-tuple-element.22, u8[3]{0} %broadcast.25), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.27 = bf16[3]{0} convert(u8[3]{0} %shift-right-logical.26), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.28 = bf16[] constant(0.007812), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.29 = bf16[3]{0} broadcast(bf16[] %constant.28), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.30 = bf16[3]{0} multiply(bf16[3]{0} %convert.27, bf16[3]{0} %broadcast.29), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.13 = bf16[] constant(1), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.16 = bf16[] convert(bf16[] %constant.13), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.12 = bf16[] constant(0), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.15 = bf16[] convert(bf16[] %constant.12), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %subtract.31 = bf16[] subtract(bf16[] %convert.16, bf16[] %convert.15), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.32 = bf16[3]{0} broadcast(bf16[] %subtract.31), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.33 = bf16[3]{0} multiply(bf16[3]{0} %multiply.30, bf16[3]{0} %broadcast.32), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.34 = bf16[3]{0} broadcast(bf16[] %convert.15), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %add.35 = bf16[3]{0} add(bf16[3]{0} %multiply.33, bf16[3]{0} %broadcast.34), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.36 = bf16[3]{0} convert(bf16[3]{0} %add.35), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p2.7 = bf16[] parameter(2), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.8 = bf16[1]{0} reshape(bf16[] %p2.7), metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.9 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.8), dimensions={0}, metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.10 = bf16[] reshape(bf16[1]{0} %broadcast.9), metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.11 = bf16[3]{0} broadcast(bf16[] %reshape.10), dimensions={}, metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %compare.37 = pred[3]{0} compare(bf16[3]{0} %convert.36, bf16[3]{0} %broadcast.11), direction=LT, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.38 = bf16[3]{0} convert(pred[3]{0} %compare.37), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.39 = f32[3]{0} convert(bf16[3]{0} %convert.38), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p0.1 = f32[] parameter(0), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.40 = f32[3]{0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type=\"aten__div\" op_name=\"aten__div\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %divide.41 = f32[3]{0} divide(f32[3]{0} %convert.39, f32[3]{0} %broadcast.40), metadata={op_type=\"aten__div\" op_name=\"aten__div\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.42 = bf16[3]{0} convert(f32[3]{0} %divide.41), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.43 = f32[3]{0} convert(bf16[3]{0} %convert.42), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.46 = f32[3]{0} multiply(f32[3]{0} %convert.45, f32[3]{0} %convert.43), metadata={op_type=\"aten__mul\" op_name=\"aten__mul.1/aten__mul\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.47 = bf16[3]{0} convert(f32[3]{0} %multiply.46), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  ROOT %tuple.48 = (bf16[3]{0}) tuple(bf16[3]{0} %convert.47)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch_xla.sync()\n",
    "drop = nn.Dropout(p=0.5)\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.bfloat16)\n",
    "y = drop(x)\n",
    "ctx = torch_xla._XLAC.lowering.LoweringContext()\n",
    "ctx.build([y])\n",
    "mapping_5 = ctx.parameter_id_tensor_mapping()\n",
    "hlo_5 = torch_xla._XLAC._get_xla_tensors_hlo([y])\n",
    "print(hlo_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetRngSeed of device 0x55e4ac9fc260\n",
      "Init seed value from scalar: 4973168205254853\n",
      "Update seed to: 12858234909764943988\n",
      "HloModule IrToHlo.49, entry_computation_layout={(f32[], s64[], bf16[], bf16[3]{0})->(bf16[3]{0})}\n",
      "\n",
      "ENTRY %IrToHlo.49 (p0.1: f32[], p1.2: s64[], p2.7: bf16[], p3.44: bf16[3]) -> (bf16[3]) {\n",
      "  %constant.5 = s64[] constant(2531011), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.3 = s64[] constant(214013), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p1.2 = s64[] parameter(1), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.4 = s64[] multiply(s64[] %constant.3, s64[] %p1.2), metadata={op_type=\"aten__mul\" op_name=\"aten__mul\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %add.6 = s64[] add(s64[] %constant.5, s64[] %multiply.4), metadata={op_type=\"aten__add\" op_name=\"aten__add\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.14 = u64[] convert(s64[] %add.6), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.18 = u64[1]{0} reshape(u64[] %convert.14), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.17 = u64[] constant(0), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.19 = u64[1]{0} reshape(u64[] %constant.17), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %concatenate.20 = u64[2]{0} concatenate(u64[1]{0} %reshape.18, u64[1]{0} %reshape.19), dimensions={0}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %rng-bit-generator.21 = (u64[2]{0}, u8[3]{0}) rng-bit-generator(u64[2]{0} %concatenate.20), algorithm=rng_default, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %get-tuple-element.23 = u64[2]{0} get-tuple-element((u64[2]{0}, u8[3]{0}) %rng-bit-generator.21), index=0, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p3.44 = bf16[3]{0} parameter(3), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/utils/_device.py\" source_line=106}\n",
      "  %convert.45 = f32[3]{0} convert(bf16[3]{0} %p3.44), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %get-tuple-element.22 = u8[3]{0} get-tuple-element((u64[2]{0}, u8[3]{0}) %rng-bit-generator.21), index=1, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.24 = u8[] constant(1), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.25 = u8[3]{0} broadcast(u8[] %constant.24), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %shift-right-logical.26 = u8[3]{0} shift-right-logical(u8[3]{0} %get-tuple-element.22, u8[3]{0} %broadcast.25), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.27 = bf16[3]{0} convert(u8[3]{0} %shift-right-logical.26), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.28 = bf16[] constant(0.007812), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.29 = bf16[3]{0} broadcast(bf16[] %constant.28), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.30 = bf16[3]{0} multiply(bf16[3]{0} %convert.27, bf16[3]{0} %broadcast.29), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.13 = bf16[] constant(1), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.16 = bf16[] convert(bf16[] %constant.13), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %constant.12 = bf16[] constant(0), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.15 = bf16[] convert(bf16[] %constant.12), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %subtract.31 = bf16[] subtract(bf16[] %convert.16, bf16[] %convert.15), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.32 = bf16[3]{0} broadcast(bf16[] %subtract.31), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.33 = bf16[3]{0} multiply(bf16[3]{0} %multiply.30, bf16[3]{0} %broadcast.32), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.34 = bf16[3]{0} broadcast(bf16[] %convert.15), dimensions={}, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %add.35 = bf16[3]{0} add(bf16[3]{0} %multiply.33, bf16[3]{0} %broadcast.34), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.36 = bf16[3]{0} convert(bf16[3]{0} %add.35), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p2.7 = bf16[] parameter(2), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.8 = bf16[1]{0} reshape(bf16[] %p2.7), metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.9 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.8), dimensions={0}, metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %reshape.10 = bf16[] reshape(bf16[1]{0} %broadcast.9), metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.11 = bf16[3]{0} broadcast(bf16[] %reshape.10), dimensions={}, metadata={op_type=\"aten__expand\" op_name=\"aten__expand\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %compare.37 = pred[3]{0} compare(bf16[3]{0} %convert.36, bf16[3]{0} %broadcast.11), direction=LT, metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.38 = bf16[3]{0} convert(pred[3]{0} %compare.37), metadata={op_type=\"aten__bernoulli\" op_name=\"aten__bernoulli\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.39 = f32[3]{0} convert(bf16[3]{0} %convert.38), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %p0.1 = f32[] parameter(0), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %broadcast.40 = f32[3]{0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type=\"aten__div\" op_name=\"aten__div\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %divide.41 = f32[3]{0} divide(f32[3]{0} %convert.39, f32[3]{0} %broadcast.40), metadata={op_type=\"aten__div\" op_name=\"aten__div\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.42 = bf16[3]{0} convert(f32[3]{0} %divide.41), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.43 = f32[3]{0} convert(bf16[3]{0} %convert.42), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %multiply.46 = f32[3]{0} multiply(f32[3]{0} %convert.45, f32[3]{0} %convert.43), metadata={op_type=\"aten__mul\" op_name=\"aten__mul.1/aten__mul\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  %convert.47 = bf16[3]{0} convert(f32[3]{0} %multiply.46), metadata={op_type=\"xla__cast\" op_name=\"xla__cast\" source_file=\"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\" source_line=1425}\n",
      "  ROOT %tuple.48 = (bf16[3]{0}) tuple(bf16[3]{0} %convert.47)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch_xla.sync()\n",
    "drop = nn.Dropout(p=0.1)\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.bfloat16)\n",
    "y = drop(x)\n",
    "ctx = torch_xla._XLAC.lowering.LoweringContext()\n",
    "ctx.build([y])\n",
    "mapping_1 = ctx.parameter_id_tensor_mapping()\n",
    "hlo_1 = torch_xla._XLAC._get_xla_tensors_hlo([y])\n",
    "print(hlo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: why are these HLOs the same?\n",
    "# Answer: every time we `mark_step`, the `devctx->seed_ir_value` Lazy IR value gets\n",
    "# reset back to an empty value, essentially resetting the Lazy IR graph representing the\n",
    "# seed updates. In addition, the `devctx->seed` value gets updated according to a formula\n",
    "# devctx->seed = 1012031 + devctx->seed * 7012063, so the next time the RNG is invoked,\n",
    "# we'll get a different `devctx->seed_ir_value`.\n",
    "hlo_1 == hlo_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from difflib import unified_diff\n",
    "sys.stdout.writelines(unified_diff(hlo_1, hlo_5, fromfile=\"hlo1\", tofile=\"hlo5\", n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: (torch.Tensor, 140268645422064),\n",
       " 2: (torch.Tensor, 140281431535632),\n",
       " 1: (torch.Tensor, 140268666958160),\n",
       " 0: (torch.Tensor, 140268610811232)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ k: (type(v), id(v)) for k, v in mapping_1.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: (torch.Tensor, 140281580106144),\n",
       " 2: (torch.Tensor, 140268610983056),\n",
       " 1: (torch.Tensor, 140268610983376),\n",
       " 0: (torch.Tensor, 140268610982896)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ k: (type(v), id(v)) for k, v in mapping_5.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], dtype=torch.bfloat16),\n",
       " tensor([1., 2., 3.], dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_1[3], mapping_5[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9000), tensor(0.5000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_1[0], mapping_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8984, dtype=torch.bfloat16), tensor(0.5000, dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_1[2], mapping_5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4973168205254853), tensor(709230394))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the random seed.\n",
    "mapping_1[1], mapping_5[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test again but don't mark step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
