{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLO for forward:\n",
      "digraph G {\n",
      "  node0 [label=\"xla::device_data\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node1 [label=\"xla::device_data\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node2 [label=\"aten::permute\\nf32[32,10]{0,1}\\nxla_shape=f32[32,10]{0,1}\"]\n",
      "  node3 [label=\"xla::device_data\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node4 [label=\"xla::device_data\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node5 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node6 [label=\"xla::device_data\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node7 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node8 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node9 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node10 [label=\"aten::addmm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node11 [label=\"aten::sin\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node12 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node13 [label=\"aten::sin\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node14 [label=\"aten::addmm\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node15 [label=\"aten::sin\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\\nROOT=0\"]\n",
      "  node14 -> node15\n",
      "  node13 -> node14 [label=\"i=0\"]\n",
      "  node2 -> node14 [label=\"i=1\"]\n",
      "  node0 -> node14 [label=\"i=2\"]\n",
      "  node12 -> node13\n",
      "  node11 -> node12 [label=\"i=0\"]\n",
      "  node5 -> node12 [label=\"i=1\"]\n",
      "  node3 -> node12 [label=\"i=2\"]\n",
      "  node10 -> node11\n",
      "  node9 -> node10 [label=\"i=0\"]\n",
      "  node8 -> node10 [label=\"i=1\"]\n",
      "  node6 -> node10 [label=\"i=2\"]\n",
      "  node7 -> node8\n",
      "  node4 -> node5\n",
      "  node1 -> node2\n",
      "}\n",
      "\n",
      "HLO for forward + backward:\n",
      "digraph G {\n",
      "  node0 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node1 [label=\"xla::device_data\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node2 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node3 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node4 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node5 [label=\"aten::addmm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node6 [label=\"aten::cos\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node7 [label=\"xla::device_data\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node8 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node9 [label=\"aten::permute\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node10 [label=\"xla::device_data\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node11 [label=\"aten::sin\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node12 [label=\"xla::optimization_barrier\\n(f32[64,64]{1,0})\\nxla_shape=(f32[64,64]{1,0})\"]\n",
      "  node13 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node14 [label=\"aten::cos\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node15 [label=\"xla::device_data\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node16 [label=\"aten::permute\\nf32[32,10]{0,1}\\nxla_shape=f32[32,10]{0,1}\"]\n",
      "  node17 [label=\"aten::permute\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node18 [label=\"xla::device_data\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node19 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node20 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node21 [label=\"aten::sin\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node22 [label=\"aten::addmm\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node23 [label=\"aten::cos\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node24 [label=\"prim::Constant\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node25 [label=\"aten::expand\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node26 [label=\"aten::expand\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node27 [label=\"aten::mul\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node28 [label=\"aten::mm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node29 [label=\"aten::mul\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node30 [label=\"aten::mm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node31 [label=\"aten::mul\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node32 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node33 [label=\"aten::mm\\nf32[128,64]{1,0}\\nxla_shape=f32[128,64]{1,0}\"]\n",
      "  node34 [label=\"aten::permute\\nf32[64,128]{0,1}\\nxla_shape=f32[64,128]{0,1}\"]\n",
      "  node35 [label=\"aten::add\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\\nROOT=0\"]\n",
      "  node36 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node37 [label=\"aten::sum\\nf32[1,64]{1,0}\\nxla_shape=f32[1,64]{1,0}\"]\n",
      "  node38 [label=\"aten::view\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node39 [label=\"aten::add\\nf32[64]{0}\\nxla_shape=f32[64]{0}\\nROOT=1\"]\n",
      "  node40 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node41 [label=\"aten::permute\\nf32[64,64]{0,1}\\nxla_shape=f32[64,64]{0,1}\"]\n",
      "  node42 [label=\"aten::mm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node43 [label=\"aten::permute\\nf32[32,64]{0,1}\\nxla_shape=f32[32,64]{0,1}\"]\n",
      "  node44 [label=\"aten::add\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\\nROOT=2\"]\n",
      "  node45 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node46 [label=\"aten::sum\\nf32[1,32]{1,0}\\nxla_shape=f32[1,32]{1,0}\"]\n",
      "  node47 [label=\"aten::view\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node48 [label=\"aten::add\\nf32[32]{0}\\nxla_shape=f32[32]{0}\\nROOT=3\"]\n",
      "  node49 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node50 [label=\"aten::permute\\nf32[32,64]{0,1}\\nxla_shape=f32[32,64]{0,1}\"]\n",
      "  node51 [label=\"aten::mm\\nf32[32,10]{1,0}\\nxla_shape=f32[32,10]{1,0}\"]\n",
      "  node52 [label=\"aten::permute\\nf32[10,32]{0,1}\\nxla_shape=f32[10,32]{0,1}\"]\n",
      "  node53 [label=\"aten::add\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\\nROOT=4\"]\n",
      "  node54 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node55 [label=\"aten::sum\\nf32[1,10]{1,0}\\nxla_shape=f32[1,10]{1,0}\"]\n",
      "  node56 [label=\"aten::view\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node57 [label=\"aten::add\\nf32[10]{0}\\nxla_shape=f32[10]{0}\\nROOT=5\"]\n",
      "  node58 [label=\"aten::sin\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\\nROOT=7\"]\n",
      "  node59 [label=\"aten::sum\\nf32[]\\nxla_shape=f32[]\\nROOT=6\"]\n",
      "  node58 -> node59\n",
      "  node22 -> node58\n",
      "  node18 -> node57 [label=\"i=0\"]\n",
      "  node56 -> node57 [label=\"i=1\"]\n",
      "  node54 -> node57 [label=\"i=2\"]\n",
      "  node55 -> node56\n",
      "  node27 -> node55\n",
      "  node15 -> node53 [label=\"i=0\"]\n",
      "  node52 -> node53 [label=\"i=1\"]\n",
      "  node49 -> node53 [label=\"i=2\"]\n",
      "  node51 -> node52\n",
      "  node50 -> node51 [label=\"i=0\"]\n",
      "  node27 -> node51 [label=\"i=1\"]\n",
      "  node21 -> node50\n",
      "  node10 -> node48 [label=\"i=0\"]\n",
      "  node47 -> node48 [label=\"i=1\"]\n",
      "  node45 -> node48 [label=\"i=2\"]\n",
      "  node46 -> node47\n",
      "  node29 -> node46\n",
      "  node7 -> node44 [label=\"i=0\"]\n",
      "  node43 -> node44 [label=\"i=1\"]\n",
      "  node40 -> node44 [label=\"i=2\"]\n",
      "  node42 -> node43\n",
      "  node41 -> node42 [label=\"i=0\"]\n",
      "  node29 -> node42 [label=\"i=1\"]\n",
      "  node12 -> node41\n",
      "  node1 -> node39 [label=\"i=0\"]\n",
      "  node38 -> node39 [label=\"i=1\"]\n",
      "  node36 -> node39 [label=\"i=2\"]\n",
      "  node37 -> node38\n",
      "  node31 -> node37\n",
      "  node2 -> node35 [label=\"i=0\"]\n",
      "  node34 -> node35 [label=\"i=1\"]\n",
      "  node0 -> node35 [label=\"i=2\"]\n",
      "  node33 -> node34\n",
      "  node32 -> node33 [label=\"i=0\"]\n",
      "  node31 -> node33 [label=\"i=1\"]\n",
      "  node4 -> node32\n",
      "  node30 -> node31 [label=\"i=0\"]\n",
      "  node6 -> node31 [label=\"i=1\"]\n",
      "  node29 -> node30 [label=\"i=0\"]\n",
      "  node9 -> node30 [label=\"i=1\"]\n",
      "  node28 -> node29 [label=\"i=0\"]\n",
      "  node14 -> node29 [label=\"i=1\"]\n",
      "  node27 -> node28 [label=\"i=0\"]\n",
      "  node17 -> node28 [label=\"i=1\"]\n",
      "  node26 -> node27 [label=\"i=0\"]\n",
      "  node23 -> node27 [label=\"i=1\"]\n",
      "  node25 -> node26\n",
      "  node24 -> node25\n",
      "  node22 -> node23\n",
      "  node21 -> node22 [label=\"i=0\"]\n",
      "  node16 -> node22 [label=\"i=1\"]\n",
      "  node18 -> node22 [label=\"i=2\"]\n",
      "  node20 -> node21\n",
      "  node11 -> node20 [label=\"i=0\"]\n",
      "  node19 -> node20 [label=\"i=1\"]\n",
      "  node10 -> node20 [label=\"i=2\"]\n",
      "  node7 -> node19\n",
      "  node16 -> node17\n",
      "  node15 -> node16\n",
      "  node13 -> node14\n",
      "  node12 -> node13 [label=\"i=0\"]\n",
      "  node8 -> node13 [label=\"i=1\"]\n",
      "  node10 -> node13 [label=\"i=2\"]\n",
      "  node11 -> node12\n",
      "  node5 -> node11\n",
      "  node8 -> node9\n",
      "  node7 -> node8\n",
      "  node5 -> node6\n",
      "  node4 -> node5 [label=\"i=0\"]\n",
      "  node3 -> node5 [label=\"i=1\"]\n",
      "  node1 -> node5 [label=\"i=2\"]\n",
      "  node2 -> node3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.utils.checkpoint\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "\n",
    "  def __init__(self, checkpoint=True):\n",
    "    super(SimpleMLP, self).__init__()\n",
    "    self.checkpoint = checkpoint\n",
    "    self.fc1 = nn.Linear(128, 64)\n",
    "    self.fc2 = nn.Linear(64, 32)\n",
    "    self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = torch.sin(x)\n",
    "    if self.checkpoint:\n",
    "      x = torch_xla.utils.checkpoint.checkpoint(self.block, x)\n",
    "    else:\n",
    "      x = self.block(x)\n",
    "    x = self.fc3(x)\n",
    "    x = torch.sin(x)\n",
    "    return x\n",
    "\n",
    "  def block(self, x):\n",
    "    x = self.fc2(x)\n",
    "    x = torch.sin(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Dummy data\n",
    "device = xm.xla_device()\n",
    "dummy_data = torch.randn(64, 128, device=device)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = SimpleMLP(checkpoint=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # type:ignore\n",
    "\n",
    "# Cut the graph here\n",
    "xm.mark_step()\n",
    "\n",
    "# Training step with gradient checkpointing\n",
    "optimizer.zero_grad()\n",
    "x = model(dummy_data)\n",
    "assert x is not None\n",
    "\n",
    "print(\"HLO for forward:\")\n",
    "ir = torch_xla._XLAC._get_xla_tensors_dot([x])\n",
    "print(ir)\n",
    "\n",
    "dummy_loss = x.sum()\n",
    "dummy_loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print the HLO graph for the forward + backward pass\n",
    "print(\"HLO for forward + backward:\")\n",
    "optimizable_tensors = [p for p in model.parameters() if p.grad is not None]\n",
    "ir = torch_xla._XLAC._get_xla_tensors_dot(optimizable_tensors + [dummy_loss, x])\n",
    "print(ir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLO for forward:\n",
      "digraph G {\n",
      "  node0 [label=\"xla::device_data\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node1 [label=\"xla::device_data\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node2 [label=\"aten::permute\\nf32[32,10]{0,1}\\nxla_shape=f32[32,10]{0,1}\"]\n",
      "  node3 [label=\"xla::device_data\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node4 [label=\"xla::device_data\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node5 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node6 [label=\"xla::device_data\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node7 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node8 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node9 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node10 [label=\"aten::addmm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node11 [label=\"aten::sin\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node12 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node13 [label=\"aten::sin\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node14 [label=\"aten::addmm\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node15 [label=\"aten::sin\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\\nROOT=0\"]\n",
      "  node14 -> node15\n",
      "  node13 -> node14 [label=\"i=0\"]\n",
      "  node2 -> node14 [label=\"i=1\"]\n",
      "  node0 -> node14 [label=\"i=2\"]\n",
      "  node12 -> node13\n",
      "  node11 -> node12 [label=\"i=0\"]\n",
      "  node5 -> node12 [label=\"i=1\"]\n",
      "  node3 -> node12 [label=\"i=2\"]\n",
      "  node10 -> node11\n",
      "  node9 -> node10 [label=\"i=0\"]\n",
      "  node8 -> node10 [label=\"i=1\"]\n",
      "  node6 -> node10 [label=\"i=2\"]\n",
      "  node7 -> node8\n",
      "  node4 -> node5\n",
      "  node1 -> node2\n",
      "}\n",
      "\n",
      "Do backward pass\n",
      "Enter MarkInputsToRegion\n",
      "Exit MarkInputsToRegion\n",
      "HLO for forward + backward:\n",
      "digraph G {\n",
      "  node0 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node1 [label=\"xla::device_data\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node2 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node3 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node4 [label=\"xla::device_data\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\"]\n",
      "  node5 [label=\"aten::addmm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node6 [label=\"aten::cos\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node7 [label=\"xla::device_data\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node8 [label=\"xla::optimization_barrier\\n(f32[32,64]{1,0})\\nxla_shape=(f32[32,64]{1,0})\"]\n",
      "  node9 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node10 [label=\"aten::permute\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\"]\n",
      "  node11 [label=\"xla::device_data\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node12 [label=\"xla::optimization_barrier\\n(f32[32]{0})\\nxla_shape=(f32[32]{0})\"]\n",
      "  node13 [label=\"aten::sin\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node14 [label=\"xla::optimization_barrier\\n(f32[64,64]{1,0})\\nxla_shape=(f32[64,64]{1,0})\"]\n",
      "  node15 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node16 [label=\"aten::cos\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node17 [label=\"xla::device_data\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node18 [label=\"aten::permute\\nf32[32,10]{0,1}\\nxla_shape=f32[32,10]{0,1}\"]\n",
      "  node19 [label=\"aten::permute\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\"]\n",
      "  node20 [label=\"xla::device_data\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node21 [label=\"aten::permute\\nf32[64,32]{0,1}\\nxla_shape=f32[64,32]{0,1}\"]\n",
      "  node22 [label=\"aten::addmm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node23 [label=\"aten::sin\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node24 [label=\"aten::addmm\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node25 [label=\"aten::cos\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node26 [label=\"prim::Constant\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node27 [label=\"aten::expand\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node28 [label=\"aten::expand\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node29 [label=\"aten::mul\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\"]\n",
      "  node30 [label=\"aten::mm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node31 [label=\"aten::mul\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node32 [label=\"aten::mm\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node33 [label=\"aten::mul\\nf32[64,64]{1,0}\\nxla_shape=f32[64,64]{1,0}\"]\n",
      "  node34 [label=\"aten::permute\\nf32[128,64]{0,1}\\nxla_shape=f32[128,64]{0,1}\"]\n",
      "  node35 [label=\"aten::mm\\nf32[128,64]{1,0}\\nxla_shape=f32[128,64]{1,0}\"]\n",
      "  node36 [label=\"aten::permute\\nf32[64,128]{0,1}\\nxla_shape=f32[64,128]{0,1}\"]\n",
      "  node37 [label=\"aten::add\\nf32[64,128]{1,0}\\nxla_shape=f32[64,128]{1,0}\\nROOT=0\"]\n",
      "  node38 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node39 [label=\"aten::sum\\nf32[1,64]{1,0}\\nxla_shape=f32[1,64]{1,0}\"]\n",
      "  node40 [label=\"aten::view\\nf32[64]{0}\\nxla_shape=f32[64]{0}\"]\n",
      "  node41 [label=\"aten::add\\nf32[64]{0}\\nxla_shape=f32[64]{0}\\nROOT=1\"]\n",
      "  node42 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node43 [label=\"aten::permute\\nf32[64,64]{0,1}\\nxla_shape=f32[64,64]{0,1}\"]\n",
      "  node44 [label=\"aten::mm\\nf32[64,32]{1,0}\\nxla_shape=f32[64,32]{1,0}\"]\n",
      "  node45 [label=\"aten::permute\\nf32[32,64]{0,1}\\nxla_shape=f32[32,64]{0,1}\"]\n",
      "  node46 [label=\"aten::add\\nf32[32,64]{1,0}\\nxla_shape=f32[32,64]{1,0}\\nROOT=2\"]\n",
      "  node47 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node48 [label=\"aten::sum\\nf32[1,32]{1,0}\\nxla_shape=f32[1,32]{1,0}\"]\n",
      "  node49 [label=\"aten::view\\nf32[32]{0}\\nxla_shape=f32[32]{0}\"]\n",
      "  node50 [label=\"aten::add\\nf32[32]{0}\\nxla_shape=f32[32]{0}\\nROOT=3\"]\n",
      "  node51 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node52 [label=\"aten::permute\\nf32[32,64]{0,1}\\nxla_shape=f32[32,64]{0,1}\"]\n",
      "  node53 [label=\"aten::mm\\nf32[32,10]{1,0}\\nxla_shape=f32[32,10]{1,0}\"]\n",
      "  node54 [label=\"aten::permute\\nf32[10,32]{0,1}\\nxla_shape=f32[10,32]{0,1}\"]\n",
      "  node55 [label=\"aten::add\\nf32[10,32]{1,0}\\nxla_shape=f32[10,32]{1,0}\\nROOT=4\"]\n",
      "  node56 [label=\"xla::device_data\\nf32[]\\nxla_shape=f32[]\"]\n",
      "  node57 [label=\"aten::sum\\nf32[1,10]{1,0}\\nxla_shape=f32[1,10]{1,0}\"]\n",
      "  node58 [label=\"aten::view\\nf32[10]{0}\\nxla_shape=f32[10]{0}\"]\n",
      "  node59 [label=\"aten::add\\nf32[10]{0}\\nxla_shape=f32[10]{0}\\nROOT=5\"]\n",
      "  node60 [label=\"aten::sin\\nf32[64,10]{1,0}\\nxla_shape=f32[64,10]{1,0}\\nROOT=7\"]\n",
      "  node61 [label=\"aten::sum\\nf32[]\\nxla_shape=f32[]\\nROOT=6\"]\n",
      "  node60 -> node61\n",
      "  node24 -> node60\n",
      "  node20 -> node59 [label=\"i=0\"]\n",
      "  node58 -> node59 [label=\"i=1\"]\n",
      "  node56 -> node59 [label=\"i=2\"]\n",
      "  node57 -> node58\n",
      "  node29 -> node57\n",
      "  node17 -> node55 [label=\"i=0\"]\n",
      "  node54 -> node55 [label=\"i=1\"]\n",
      "  node51 -> node55 [label=\"i=2\"]\n",
      "  node53 -> node54\n",
      "  node52 -> node53 [label=\"i=0\"]\n",
      "  node29 -> node53 [label=\"i=1\"]\n",
      "  node23 -> node52\n",
      "  node11 -> node50 [label=\"i=0\"]\n",
      "  node49 -> node50 [label=\"i=1\"]\n",
      "  node47 -> node50 [label=\"i=2\"]\n",
      "  node48 -> node49\n",
      "  node31 -> node48\n",
      "  node7 -> node46 [label=\"i=0\"]\n",
      "  node45 -> node46 [label=\"i=1\"]\n",
      "  node42 -> node46 [label=\"i=2\"]\n",
      "  node44 -> node45\n",
      "  node43 -> node44 [label=\"i=0\"]\n",
      "  node31 -> node44 [label=\"i=1\"]\n",
      "  node14 -> node43\n",
      "  node1 -> node41 [label=\"i=0\"]\n",
      "  node40 -> node41 [label=\"i=1\"]\n",
      "  node38 -> node41 [label=\"i=2\"]\n",
      "  node39 -> node40\n",
      "  node33 -> node39\n",
      "  node2 -> node37 [label=\"i=0\"]\n",
      "  node36 -> node37 [label=\"i=1\"]\n",
      "  node0 -> node37 [label=\"i=2\"]\n",
      "  node35 -> node36\n",
      "  node34 -> node35 [label=\"i=0\"]\n",
      "  node33 -> node35 [label=\"i=1\"]\n",
      "  node4 -> node34\n",
      "  node32 -> node33 [label=\"i=0\"]\n",
      "  node6 -> node33 [label=\"i=1\"]\n",
      "  node31 -> node32 [label=\"i=0\"]\n",
      "  node10 -> node32 [label=\"i=1\"]\n",
      "  node30 -> node31 [label=\"i=0\"]\n",
      "  node16 -> node31 [label=\"i=1\"]\n",
      "  node29 -> node30 [label=\"i=0\"]\n",
      "  node19 -> node30 [label=\"i=1\"]\n",
      "  node28 -> node29 [label=\"i=0\"]\n",
      "  node25 -> node29 [label=\"i=1\"]\n",
      "  node27 -> node28\n",
      "  node26 -> node27\n",
      "  node24 -> node25\n",
      "  node23 -> node24 [label=\"i=0\"]\n",
      "  node18 -> node24 [label=\"i=1\"]\n",
      "  node20 -> node24 [label=\"i=2\"]\n",
      "  node22 -> node23\n",
      "  node13 -> node22 [label=\"i=0\"]\n",
      "  node21 -> node22 [label=\"i=1\"]\n",
      "  node11 -> node22 [label=\"i=2\"]\n",
      "  node7 -> node21\n",
      "  node18 -> node19\n",
      "  node17 -> node18\n",
      "  node15 -> node16\n",
      "  node14 -> node15 [label=\"i=0\"]\n",
      "  node9 -> node15 [label=\"i=1\"]\n",
      "  node12 -> node15 [label=\"i=2\"]\n",
      "  node13 -> node14\n",
      "  node5 -> node13\n",
      "  node11 -> node12\n",
      "  node9 -> node10\n",
      "  node8 -> node9\n",
      "  node7 -> node8\n",
      "  node5 -> node6\n",
      "  node4 -> node5 [label=\"i=0\"]\n",
      "  node3 -> node5 [label=\"i=1\"]\n",
      "  node1 -> node5 [label=\"i=2\"]\n",
      "  node2 -> node3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.utils.checkpoint\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import contextlib\n",
    "from torch.utils.weak import WeakTensorKeyDictionary\n",
    "from torch.overrides import TorchFunctionMode\n",
    "from torch.utils._pytree import tree_map_only\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# TODO: solve the monkey patching\n",
    "torch.xla = torch_xla\n",
    "\n",
    "\n",
    "class MarkInputsToRegion(TorchFunctionMode):\n",
    "\n",
    "  def __init__(self, barrier_function):\n",
    "    # tensor -> bool\n",
    "    self.is_marked = WeakTensorKeyDictionary()\n",
    "    self.barrier_function = barrier_function\n",
    "  \n",
    "  def __enter__(self):\n",
    "    print(\"Enter MarkInputsToRegion\")\n",
    "    # We could handle RNG here.\n",
    "    return super().__enter__()\n",
    "\n",
    "  def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "    print(\"Exit MarkInputsToRegion\")\n",
    "    # We could handle RNG here.\n",
    "    return super().__exit__(exc_type, exc_val, exc_tb)\n",
    "\n",
    "  # This will be called on every torch function call during the\n",
    "  # recomputation of the checkpointed function.\n",
    "  def __torch_function__(self, func, types, args=(), kwargs=None):\n",
    "    if kwargs is None:\n",
    "      kwargs = {}\n",
    "\n",
    "    def visit(x):\n",
    "      # If we have not seen this tensor, wrap it with optimization barrier\n",
    "      # for this function.\n",
    "      if not self.is_marked.get(x, False):\n",
    "        val = self.barrier_function(x)\n",
    "      else:\n",
    "        val = x\n",
    "      self.is_marked[x] = True\n",
    "      return val\n",
    "\n",
    "    args = tree_map_only(torch.Tensor, visit, args)\n",
    "    kwargs = tree_map_only(torch.Tensor, visit, kwargs)\n",
    "    out = func(*args, **kwargs)\n",
    "    # Never wrap output tensors within the recomputation with optimization\n",
    "    # barrier.\n",
    "    self.is_marked[out] = True\n",
    "    return out\n",
    "\n",
    "\n",
    "def context_fn():\n",
    "\n",
    "  def barrier_function(x: torch.Tensor):\n",
    "    # Now we can do something with the input.\n",
    "    x = x.clone()\n",
    "    xm.optimization_barrier_([x])\n",
    "    return x\n",
    "\n",
    "  return contextlib.nullcontext(), MarkInputsToRegion(barrier_function)\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "\n",
    "  def __init__(self, checkpoint=True):\n",
    "    super(SimpleMLP, self).__init__()\n",
    "    self.checkpoint = checkpoint\n",
    "    self.fc1 = nn.Linear(128, 64)\n",
    "    self.fc2 = nn.Linear(64, 32)\n",
    "    self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = torch.sin(x)\n",
    "    if self.checkpoint:\n",
    "      x = checkpoint(self.block, x, context_fn=context_fn, use_reentrant=False)\n",
    "    else:\n",
    "      x = self.block(x)\n",
    "    x = self.fc3(x)\n",
    "    x = torch.sin(x)\n",
    "    return x\n",
    "\n",
    "  def block(self, x):\n",
    "    x = self.fc2(x)\n",
    "    x = torch.sin(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Dummy data\n",
    "device = xm.xla_device()\n",
    "dummy_data = torch.randn(64, 128, device=device)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = SimpleMLP(checkpoint=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # type:ignore\n",
    "\n",
    "# Cut the graph here\n",
    "xm.mark_step()\n",
    "\n",
    "# Training step with gradient checkpointing\n",
    "optimizer.zero_grad()\n",
    "x = model(dummy_data)\n",
    "assert x is not None\n",
    "\n",
    "print(\"HLO for forward:\")\n",
    "ir = torch_xla._XLAC._get_xla_tensors_dot([x])\n",
    "print(ir)\n",
    "\n",
    "print(\"Do backward pass\")\n",
    "dummy_loss = x.sum()\n",
    "dummy_loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print the HLO graph for the forward + backward pass\n",
    "print(\"HLO for forward + backward:\")\n",
    "optimizable_tensors = [p for p in model.parameters() if p.grad is not None]\n",
    "ir = torch_xla._XLAC._get_xla_tensors_dot(optimizable_tensors + [dummy_loss, x])\n",
    "print(ir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
