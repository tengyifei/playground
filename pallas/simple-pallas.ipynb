{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46835c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import torchax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ec09226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add vector result Tensor(<class 'jaxlib._jax.ArrayImpl'> [ 0.67377186  0.07321142 -2.9761477   1.3824334  -2.3937879   0.12552863\n",
      " -0.53504986 -0.64411575])\n",
      "matmul result:  Tensor(<class 'jaxlib._jax.ArrayImpl'> [[ 0.        15.863418   9.280289  ...  5.2803307  0.         0.       ]\n",
      " [ 9.733851   0.         5.2965965 ...  0.         0.        54.980007 ]\n",
      " [ 0.         0.        31.144966  ...  0.        18.25214   43.20775  ]\n",
      " ...\n",
      " [ 0.        10.782309  25.80857   ...  0.        13.586363  58.227524 ]\n",
      " [23.757692   0.         0.        ... 38.23269   11.854513   0.       ]\n",
      " [ 7.3983526 32.635433  13.593995  ... 28.632645  40.917164   0.       ]])\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from jax.experimental import pallas as pl\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchax import interop\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Copy of https://github.com/qihqi/learning_machine/tree/main/torch_pallas\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "torchax.enable_globally()\n",
    "\n",
    "\n",
    "def torch_pallas_call(kernel, *args, **kwargs):\n",
    "  kernel_as_jax = interop.jax_view(kernel)\n",
    "  orig_pallas_callable = pl.pallas_call(\n",
    "      kernel_as_jax,\n",
    "      *args,\n",
    "      **kwargs,\n",
    "  )\n",
    "  return interop.torch_view(orig_pallas_callable)\n",
    "\n",
    "\n",
    "# https://docs.jax.dev/en/latest/pallas/quickstart.html\n",
    "# easiest hello world\n",
    "def add_vectors_kernel(x_ref, y_ref, o_ref):\n",
    "  x, y = x_ref[...], y_ref[...]\n",
    "  o_ref[...] = torch.add(x, y)\n",
    "\n",
    "\n",
    "  \n",
    "def add_vectors(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "  return torch_pallas_call(\n",
    "      add_vectors_kernel,\n",
    "      out_shape=jax.ShapeDtypeStruct(x.shape, interop.jax_view(x.dtype)),\n",
    "      interpret=True\n",
    "  )(x, y)\n",
    "\n",
    "print('add vector result', add_vectors(torch.randn(8, device='jax'), torch.randn(8, device='jax')))\n",
    "\n",
    "\n",
    "# =====  matmul example ===\n",
    "def matmul_kernel(x_ref, y_ref, z_ref, *, activation):\n",
    "  z_ref[...] = activation(torch.matmul(x_ref[...], y_ref[...]))\n",
    "\n",
    "def matmul(x: torch.Tensor, y: torch.Tensor, *, activation):\n",
    "  return torch_pallas_call(\n",
    "    functools.partial(matmul_kernel, activation=activation),\n",
    "    out_shape=jax.ShapeDtypeStruct((x.shape[0], y.shape[1]), interop.jax_view(x.dtype)),\n",
    "    grid=(2, 2),\n",
    "    in_specs=[\n",
    "        pl.BlockSpec((x.shape[0] // 2, x.shape[1]), lambda i, j: (i, 0)),\n",
    "        pl.BlockSpec((y.shape[0], y.shape[1] // 2), lambda i, j: (0, j))\n",
    "    ],\n",
    "    out_specs=pl.BlockSpec(\n",
    "        (x.shape[0] // 2, y.shape[1] // 2), lambda i, j: (i, j)\n",
    "    ),\n",
    "    interpret=True,\n",
    "  )(x, y)\n",
    "\n",
    "a = torch.randn((1024, 1024), device='jax')\n",
    "b = torch.randn((1024, 1024), device='jax')\n",
    "\n",
    "\n",
    "z = matmul(a, b, activation=torch.nn.functional.relu)\n",
    "print('matmul result: ', z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfcaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_kernel(x_ref, y_ref, o_ref):\n",
    "  x, y = x_ref[...], y_ref[...]\n",
    "  o_ref[...] = x + y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acb29cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[2,2] b:f32[2,2]. let\n",
       "    c:f32[2,2] = pallas_call[\n",
       "      backend=None\n",
       "      compiler_params={}\n",
       "      cost_estimate=None\n",
       "      debug=True\n",
       "      grid_mapping=GridMapping(grid=(), grid_names=None, block_mappings=(BlockMapping(block_shape=(Blocked(block_size=2), Blocked(block_size=2)), transformed_block_aval=MemRef<None>{float32[2,2]}, index_map_jaxpr={ lambda ; . let  in (0, 0) }, array_shape_dtype=ShapeDtypeStruct(shape=(2, 2), dtype=float32), origin='args[0]', transforms=(), pipeline_mode=None), BlockMapping(block_shape=(Blocked(block_size=2), Blocked(block_size=2)), transformed_block_aval=MemRef<None>{float32[2,2]}, index_map_jaxpr={ lambda ; . let  in (0, 0) }, array_shape_dtype=ShapeDtypeStruct(shape=(2, 2), dtype=float32), origin='args[1]', transforms=(), pipeline_mode=None), BlockMapping(block_shape=(Blocked(block_size=2), Blocked(block_size=2)), transformed_block_aval=MemRef<None>{float32[2,2]}, index_map_jaxpr={ lambda ; . let  in (0, 0) }, array_shape_dtype=ShapeDtypeStruct(shape=(2, 2), dtype=float32), origin='outputs', transforms=(), pipeline_mode=None)), index_map_tree=PyTreeDef(((), {})), index_map_avals=(), vmapped_dims=(), num_index_operands=0, num_inputs=2, num_outputs=1, num_scratch_operands=0, get_grid_indices=None, local_grid_env=None)\n",
       "      input_output_aliases=()\n",
       "      interpret=False\n",
       "      jaxpr={ lambda ; d:MemRef<None>{float32[2,2]} e:MemRef<None>{float32[2,2]}\n",
       "          f:MemRef<None>{float32[2,2]}. let\n",
       "          g:f32[2,2] <- d[:,:]\n",
       "          h:f32[2,2] <- e[:,:]\n",
       "          i:f32[2,2] = add g h\n",
       "          f[:,:] <- i\n",
       "        in () }\n",
       "      mesh=None\n",
       "      out_avals=(ShapedArray(float32[2,2]),)\n",
       "    ] a b\n",
       "  in (c,) }"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lifted = pl.pallas_call(\n",
    "  simple_kernel,\n",
    "  out_shape=jax.ShapeDtypeStruct((2, 2), jnp.float32),\n",
    "  debug=True,\n",
    ")\n",
    "jaxpr = jax.make_jaxpr(lifted)(jnp.ones((2, 2)), jnp.ones((2, 2)))\n",
    "jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "722dfc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a:f32[2,2] <- b[:,:], a:f32[2,2] <- b[:,:], a:f32[2,2] = add b c, a[:,:] <- b]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_jaxpr = jaxpr.eqns[0].params['jaxpr']\n",
    "inner_jaxpr.eqns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8688dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:f32[2,2] <- b[:,:] # get <class 'jax._src.core.Primitive'>\n",
      "a:f32[2,2] <- b[:,:] # get <class 'jax._src.core.Primitive'>\n",
      "a:f32[2,2] = add b c # add <class 'jax._src.core.Primitive'>\n",
      "a[:,:] <- b # swap <class 'jax._src.core.Primitive'>\n"
     ]
    }
   ],
   "source": [
    "for eqn in inner_jaxpr.eqns:\n",
    "  print(eqn, '#', eqn.primitive, type(eqn.primitive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051bbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
