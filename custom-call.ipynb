{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "\n",
    "\n",
    "@torch.library.custom_op(\"xla::name_tensor\", mutates_args=())\n",
    "def name_tensor(t: torch.Tensor, name: str) -> torch.Tensor:\n",
    "  if t is None:\n",
    "    return None\n",
    "  return t.clone()\n",
    "\n",
    "\n",
    "@name_tensor.register_fake\n",
    "def _(t: torch.Tensor, name: str) -> torch.Tensor:\n",
    "  if t is None:\n",
    "    return None\n",
    "  return torch.empty_like(t)\n",
    "\n",
    "\n",
    "def name_tensor_backward(ctx, grad):\n",
    "  return grad, None\n",
    "\n",
    "\n",
    "name_tensor.register_autograd(name_tensor_backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(10)\n",
    "a = name_tensor(a, \"foo\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch.compile import aot_function, make_boxed_func  # type: ignore\n",
    "a = torch.ones(10, requires_grad=True)\n",
    "def my_fn(x):\n",
    "  return name_tensor(x, \"foo\")\n",
    "graphs = []\n",
    "def get_graph(gm: torch.fx.GraphModule, _):\n",
    "  graphs.append(gm)\n",
    "  return make_boxed_func(gm)\n",
    "\n",
    "c = aot_function(my_fn, get_graph)(a)\n",
    "c.sum().backward()\n",
    "assert len(graphs) == 2\n",
    "fw, bw = graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_1):\n",
      "    name_tensor = torch.ops.xla.name_tensor.default(primals_1, 'foo');  primals_1 = None\n",
      "    return (name_tensor,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(fw.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name         target                   args                kwargs\n",
      "-------------  -----------  -----------------------  ------------------  --------\n",
      "placeholder    primals_1    primals_1                ()                  {}\n",
      "call_function  name_tensor  xla.name_tensor.default  (primals_1, 'foo')  {}\n",
      "output         output       output                   ((name_tensor,),)   {}\n"
     ]
    }
   ],
   "source": [
    "fw.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primals_1 {'val': FakeTensor(..., size=(10,)), 'tensor_meta': TensorMetadata(shape=torch.Size([10]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}\n",
      "name_tensor {'original_aten': <OpOverload(op='xla.name_tensor', overload='default')>, 'seq_nr': 27, 'val': FakeTensor(..., size=(10,)), 'tensor_meta': TensorMetadata(shape=torch.Size([10]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}\n",
      "output {}\n"
     ]
    }
   ],
   "source": [
    "fw: torch.fx.GraphModule = fw\n",
    "for node in fw.graph.nodes:\n",
    "  print(node.name, node.meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, tangents_1):\n",
      "    return (tangents_1,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(bw.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what?\n",
    "\n",
    "Similar to the `checkpoint_name` in JAX:\n",
    "\n",
    "```\n",
    "x = checkpoint_name(g(W1, x), name='a')\n",
    "```\n",
    "\n",
    "We can write a graph parser that figures out the name of each tensor (by walking\n",
    "the graph), then in the graph partitioner, decide whether to offload that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch.compile import min_cut_rematerialization_partition, default_partition, make_boxed_func  # type:ignore\n",
    "\n",
    "# Replicate regular torch checkpointing here. The low budget forces the partitioner\n",
    "# to recompute tensors instead of saving them.\n",
    "import torch._functorch.config\n",
    "torch._functorch.config.activation_memory_budget = 0.0\n",
    "torch._functorch.config.aggressive_recomputation = True\n",
    "torch._functorch.config.recompute_views = True\n",
    "torch._functorch.config.ban_recompute_reductions = False\n",
    "torch._functorch.config.ban_recompute_not_in_allowlist = False\n",
    "torch._functorch.config.ban_recompute_materialized_backward = False\n",
    "torch._functorch.config.ban_recompute_long_fusible_chains = False\n",
    "torch._functorch.config.ban_recompute_used_far_apart = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch.compile import aot_function, make_boxed_func  # type: ignore\n",
    "a = torch.ones(10, requires_grad=True)\n",
    "\n",
    "def my_fn(x):\n",
    "  x = name_tensor(x, \"foo\")\n",
    "  y = torch.sin(x)\n",
    "  z = y * y\n",
    "  w = z + 3\n",
    "  return w\n",
    "\n",
    "graphs = []\n",
    "def get_graph(gm: torch.fx.GraphModule, _):\n",
    "  graphs.append(gm)\n",
    "  return make_boxed_func(gm)\n",
    "\n",
    "c = aot_function(my_fn, get_graph, partition_fn=min_cut_rematerialization_partition)(a)\n",
    "c.sum().backward()\n",
    "assert len(graphs) == 2\n",
    "fw, bw = graphs\n",
    "fw: torch.fx.GraphModule = fw\n",
    "bw: torch.fx.GraphModule = bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_1):\n",
      "    name_tensor = torch.ops.xla.name_tensor.default(primals_1, 'foo')\n",
      "    sin = torch.ops.aten.sin.default(name_tensor);  name_tensor = None\n",
      "    mul = torch.ops.aten.mul.Tensor(sin, sin);  sin = None\n",
      "    add = torch.ops.aten.add.Tensor(mul, 3);  mul = None\n",
      "    return (add, primals_1)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(fw.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_1, tangents_1):\n",
      "    name_tensor = torch.ops.xla.name_tensor.default(primals_1, 'foo');  primals_1 = None\n",
      "    sin = torch.ops.aten.sin.default(name_tensor)\n",
      "    mul_1 = torch.ops.aten.mul.Tensor(tangents_1, sin);  tangents_1 = sin = None\n",
      "    add_1 = torch.ops.aten.add.Tensor(mul_1, mul_1);  mul_1 = None\n",
      "    cos = torch.ops.aten.cos.default(name_tensor);  name_tensor = None\n",
      "    mul_3 = torch.ops.aten.mul.Tensor(add_1, cos);  add_1 = cos = None\n",
      "    return (mul_3,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(bw.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{primals_1: 'foo'}\n",
      "{'foo': 1}\n"
     ]
    }
   ],
   "source": [
    "def get_named_nodes(gm: torch.fx.GraphModule):\n",
    "  named_nodes = {}\n",
    "\n",
    "  for node in gm.graph.nodes:\n",
    "    if node.op == \"call_function\":\n",
    "      if hasattr(node.target, \"name\"):\n",
    "          if node.target.name() == name_tensor._qualname:  # type: ignore\n",
    "            named_nodes[node.args[0]] = node.args[1]\n",
    "  \n",
    "  return named_nodes\n",
    "\n",
    "named_nodes = get_named_nodes(fw)\n",
    "print(named_nodes)\n",
    "\n",
    "def get_name_in_output_indices(gm: torch.fx.GraphModule):\n",
    "  named_nodes = get_named_nodes(gm)\n",
    "  name_in_output_indices = {}\n",
    "\n",
    "  for node in gm.graph.nodes:\n",
    "    if node.op == \"output\":\n",
    "      assert len(node.args) <= 1\n",
    "      if len(node.args) == 0:\n",
    "        continue\n",
    "      for i, arg in enumerate(next(iter(node.args))): # type: ignore\n",
    "        if arg in named_nodes:\n",
    "          name_in_output_indices[named_nodes[arg]] = i\n",
    "\n",
    "  return name_in_output_indices\n",
    "\n",
    "name_in_output_indices = get_name_in_output_indices(fw)\n",
    "print(name_in_output_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{primals_1: 'foo'}\n"
     ]
    }
   ],
   "source": [
    "named_nodes = get_named_nodes(bw)\n",
    "print(named_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'primals_1'}\n"
     ]
    }
   ],
   "source": [
    "name_in_input_names = {}\n",
    "\n",
    "for node in bw.graph.nodes:\n",
    "  if node.op == \"placeholder\":\n",
    "    if node in named_nodes:\n",
    "      name_in_input_names[named_nodes[node]] = node.target\n",
    "\n",
    "print(name_in_input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
