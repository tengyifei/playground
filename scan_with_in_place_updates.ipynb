{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_IR_DEBUG=1\n",
      "env: XLA_HLO_DEBUG=1\n"
     ]
    }
   ],
   "source": [
    "%env XLA_IR_DEBUG=1\n",
    "%env XLA_HLO_DEBUG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_xla.experimental.scan import scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan is tracing user fn. HLO:\n",
      "HloModule IrToHlo.18, entry_computation_layout={(f32[2]{0}, f32[2]{0}, f32[2]{0})->(f32[2]{0}, f32[2]{0})}\n",
      "\n",
      "ENTRY %IrToHlo.18 (p0.2: f32[2], p1.3: f32[2], p2.10: f32[2]) -> (f32[2], f32[2]) {\n",
      "  %p1.3 = f32[2]{0} parameter(1), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/workspaces/torch/pytorch/xla/torch_xla/experimental/scan.py\" source_line=168}\n",
      "  %p0.2 = f32[2]{0} parameter(0), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/workspaces/torch/pytorch/xla/torch_xla/experimental/scan.py\" source_line=168}\n",
      "  %constant.1 = f32[] constant(1), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=4}\n",
      "  %broadcast.4 = f32[2]{0} broadcast(f32[] %constant.1), dimensions={}, metadata={op_type=\"aten__add\" op_name=\"aten__add.1/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=4}\n",
      "  %multiply.5 = f32[2]{0} multiply(f32[2]{0} %p0.2, f32[2]{0} %broadcast.4), metadata={op_type=\"aten__add\" op_name=\"aten__add.1/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=4}\n",
      "  %add.6 = f32[2]{0} add(f32[2]{0} %p1.3, f32[2]{0} %multiply.5), metadata={op_type=\"aten__add\" op_name=\"aten__add.1/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=4}\n",
      "  %p2.10 = f32[2]{0} parameter(2), metadata={op_type=\"xla__device_data\" op_name=\"xla__device_data\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=1}\n",
      "  %constant.9 = f32[] constant(1), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=5}\n",
      "  %constant.8 = f32[] constant(1), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=5}\n",
      "  %multiply.11 = f32[] multiply(f32[] %constant.9, f32[] %constant.8), metadata={op_type=\"aten__add\" op_name=\"aten__add.2/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=5}\n",
      "  %broadcast.12 = f32[2]{0} broadcast(f32[] %multiply.11), dimensions={}, metadata={op_type=\"aten__add\" op_name=\"aten__add.2/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=5}\n",
      "  %add.13 = f32[2]{0} add(f32[2]{0} %p2.10, f32[2]{0} %broadcast.12), metadata={op_type=\"aten__add\" op_name=\"aten__add.2/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=5}\n",
      "  %constant.7 = f32[] constant(1), metadata={op_type=\"prim__Constant\" op_name=\"prim__Constant\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=6}\n",
      "  %broadcast.14 = f32[2]{0} broadcast(f32[] %constant.7), dimensions={}, metadata={op_type=\"aten__add\" op_name=\"aten__add.3/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=6}\n",
      "  %multiply.15 = f32[2]{0} multiply(f32[2]{0} %add.13, f32[2]{0} %broadcast.14), metadata={op_type=\"aten__add\" op_name=\"aten__add.3/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=6}\n",
      "  %add.16 = f32[2]{0} add(f32[2]{0} %add.6, f32[2]{0} %multiply.15), metadata={op_type=\"aten__add\" op_name=\"aten__add.3/aten__add\" source_file=\"/tmp/ipykernel_12491/2426694750.py\" source_line=6}\n",
      "  ROOT %tuple.17 = (f32[2]{0}, f32[2]{0}) tuple(f32[2]{0} %add.6, f32[2]{0} %add.16)\n",
      "}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.], device='xla:0'),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]], device='xla:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_tensor = torch.tensor([0.0, 0.0], device=torch_xla.device())\n",
    "\n",
    "def step_fn(carry, x):\n",
    "  new_carry = carry + x\n",
    "  weird_tensor.add_(1.0)\n",
    "  y = new_carry + weird_tensor\n",
    "  return new_carry, y\n",
    "\n",
    "init = torch.tensor([0.0, 0.0], device=torch_xla.device())\n",
    "xs = torch.tensor([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]], device=torch_xla.device())\n",
    "\n",
    "# Bug: because we only trace the DAG subgraph rooted at `step_fn` outputs, mutations\n",
    "# to `weird_tensor` aren't captured. TODO(yifeit): How to solve this???\n",
    "scan(step_fn, init, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.], device='xla:0'),\n",
       " tensor([[1., 1.],\n",
       "         [2., 2.],\n",
       "         [3., 3.]], device='xla:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils._pytree import tree_map, tree_flatten, tree_iter, tree_leaves, PyTree\n",
    "\n",
    "\n",
    "def loopy_scan(fn, init, xs):\n",
    "  \"\"\"A simple scan implemented with for loops serving as reference\n",
    "  implementation.\"\"\"\n",
    "  carry = init\n",
    "  ys = []\n",
    "  xs_len = len(next(iter(tree_iter(xs))))\n",
    "  for i in range(xs_len):\n",
    "    carry, y = fn(carry, tree_map(lambda x: x[i], xs))\n",
    "    ys.append(y)\n",
    "  ys = tree_map(lambda *x: torch.stack(x), *ys)\n",
    "  return carry, ys\n",
    "\n",
    "\n",
    "weird_tensor = torch.tensor([0.0, 0.0], device=torch_xla.device())\n",
    "\n",
    "def step_fn(carry, x):\n",
    "  new_carry = carry + x\n",
    "  weird_tensor.add_(1.0)\n",
    "  y = new_carry + weird_tensor\n",
    "  return new_carry, y\n",
    "\n",
    "init = torch.tensor([0.0, 0.0], device=torch_xla.device())\n",
    "xs = torch.tensor([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]], device=torch_xla.device())\n",
    "\n",
    "loopy_scan(step_fn, init, xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
